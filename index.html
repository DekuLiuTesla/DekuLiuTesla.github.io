
<!DOCTYPE html>
<html lang="en">


<!-- === Header Starts === -->
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="description" content="Yang Liu's homepage.">
  <meta name="keywords" content="Yang Liu, Zhaoxiang Zhang,
                                 UESTC, CASIA,
                                 Deep Learning, Computer Vision,
                                 Autonomous Driving, 3DGS, 3D Gaussian Splatting, NeRF, Neural Radiance Field, Large-Scale Scene Reconstruction">
  <meta name="author" content="Yang Liu">

  <title>Yang Liu</title>

  <link rel="stylesheet" type="text/css" href="assets/font-awesome-4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" type="text/css" href="assets/academicons-1.8.6/css/academicons.min.css">
  <!-- <link rel="stylesheet" type="text/css" href="assets/bootstrap-4.3.1-dist/css/bootstrap.min.css"> -->
  <link rel="stylesheet" type="text/css" href="assets/style.css">
  <link rel="icon" type="image/png" href="assets/figures/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="assets/figures/large-icon.png">
</head>
<!-- === Header Ends === -->


<body data-new-gr-c-s-check-loaded="14.1014.0" data-gr-ext-installed="">

<style>
a{text-decoration:none;}
a:link {color:#0066ff;}
a:visited {color:#0066ff;}
a:hover {color:#00ccff;}
a:active {color:#0066ff;}
</style>

<!-- === Homepage Starts === -->
<table width="980px" align="center" border="0">
<tbody>
<tr>


<td></td>  <!-- Leave one column blank on the left. -->
<td valign="top">


<!-- === Avatar Starts === -->
<br>
<table style="font-size: 12pt;" width="100%" border="0">
<tbody>
  <tr>
    <td width="30%">
      <img width="250" src="./figures/me.jpg">
    </td>

    <td>
      <div class="col-xs-12 col-sm-8">
        <h1>
          <strong>Yang Liu</strong><br>
          </h1>
            <p>
              Institute of Automation, Chinese Academy of Sciences<br>
              Beijing, 100190, P.R.China
            </p>

            <p>Email: <code>liuyang2022[at]ia.ac.cn</code></p>

            <p>
                  [<a href="https://github.com/DekuLiuTesla" target="_blank">Github</a>]
                  [<a href="https://scholar.google.com/citations?user=atD1_iMAAAAJ&hl=en" target="_blank">Google Scholar</a>]
            </p>
      </div>
    </td>
  </tr>
</tbody>
</table>
<!-- === Avatar Ends === -->


<!-- === Biography Starts === -->
<br>
<h2>Biography</h2>
<p style="font-size: 12pt; text-align: justify;">
  <p>
  Yang Liu is currently a second year Ph.D. student at
  <a href="http://cripac.ia.ac.cn/en/EN/volumn/home.shtml" target="_blank">the Center for Research on Intelligent Perception and Computing</a>,
  <a href="http://mais.ia.ac.cn/" target="_blank">State Key Laboratory of Multimodal Artificial Intelligence Systems</a>,
  <a href="http://english.ia.cas.cn/" target="_blank">Institute of Automation</a>,
  <a href="https://english.cas.cn/" target="_blank">Chinese Academy of Sciences</a>,
  under the supervision of Prof.
  <a href="https://zhaoxiangzhang.net/" target="_blank">Zhaoxiang Zhang</a>.
    
  Before that, he got his Bachelor's degree in from
  <a href="https://www.yingcai.uestc.edu.cn/" target="_blank">Yingcai Honors College</a> (Elite program of UESTC, top 109 students selected from 5000 freshmen),
  <a href="https://en.uestc.edu.cn/" target="_blank">University of Electronic Science and Technology of China (UESTC)</a> at June 2022.
  </p>

  <p>
  His research focuses on computer vision and pattern recognition,
  particularly on the following topics:
  <ul>
    <li>Novel View Synthesis</li>
    <li>Large-Scale Scene Reconstruction</li>
    <li>Robust 3D Scene Perception</li>
  </ul>
  </p>
</p>
<!-- === Biography Ends === -->


<!-- === News Starts === -->
<br>
<h2>News</h2>
<ul style="font-size: 12pt; text-align: justify;">
<table>
<tbody>
  <tr>
    <td width="30%">
      <code>06/2024</code>
    </td>
    <td>
      One paper is accepted by <strong>ECCV 2024</strong>!
    </td>
  </tr>

  <tr>
    <td width="30%">
      <code>04/2024</code>
    </td>
    <td>
      One paper is accepted by <strong>TPAMI</strong>!
    </td>
  </tr>

  <tr>
    <td width="30%">
      <code>09/2023</code>
    </td>
    <td>
      One paper is accepted by <strong>NeurIPS 2023</strong>!
    </td>
  </tr>


</tbody>
</table>

</ul>
<!-- === News Ends === -->


<!-- === Publication Starts === -->
<br>
<h2> Publications </h2>
<table cellspacing="17">
<tbody>
  <tr>
    <td width="25%">
      <img style="width: 100%; max-height: 150px; object-fit: cover;" src="./figures/projects/citygaussian.png">
    </td>
    <td>
      <strong>CityGaussian: Real-time High-quality Large-Scale Scene Rendering with Gaussians</strong>

      <br><small>
      <strong>Yang Liu</strong>,
      <font color="#7F7F7F">He Guan,</font></a>
      <a href="https://scholar.google.com/citations?hl=en&user=6iZ7VJYAAAAJ" target="_blank"><font color="#7F7F7F">Chuanchen Luo,</font></a>
      <a href="https://scholar.google.com/citations?hl=en&user=6ZzmkHEAAAAJ" target="_blank"><font color="#7F7F7F">Lue Fan,</font></a>
      <a href="https://scholar.google.com.hk/citations?user=yAWtq6QAAAAJ&hl=en&oi=ao" target="_blank"><font color="#7F7F7F">Naiyan Wang,</font></a>
      <a href="https://scholar.google.com.hk/citations?hl=en&user=xut8w_MAAAAJ" target="_blank"><font color="#7F7F7F">Junran Peng,</font></a>
      <a href="https://scholar.google.com/citations?user=qxWfV6cAAAAJ" target="_blank"><font color="#7F7F7F">Zhaoxiang Zhang</font></a>

      <br>
      [<a href="https://arxiv.org/pdf/2404.01133" target="_blank">Paper (ECCV 2024)</a>]
      [<a href="https://github.com/DekuLiuTesla/CityGaussian" target="_blank">Code</a>]
      </small>

    </td>
  </tr>

  <tr>
    <td width="25%">
      <img style="width: 100%; max-height: 150px; object-fit: cover;" src="./figures/projects/fsf.png">
    </td>
    <td>
      <strong>Fully Sparse Fusion for 3D Object Detection</strong>

      <br><small>
      <a href="https://scholar.google.com.hk/citations?hl=en&user=drB75dwAAAAJ" target="_blank"><font color="#7F7F7F">Yingyan Li,</font></a>
      <a href="https://scholar.google.com/citations?hl=en&user=6ZzmkHEAAAAJ" target="_blank"><font color="#7F7F7F">Lue Fan,</font></a>
      <strong>Yang Liu</strong>,
      <a href="https://scholar.google.com.hk/citations?hl=en&user=zXqeKPgAAAAJ" target="_blank"><font color="#7F7F7F">Zehao Huang,</font></a>
      <a href="https://scholar.google.com.hk/citations?hl=en&user=iLOoUqIAAAAJ" target="_blank"><font color="#7F7F7F">Yuntao Chen,</font></a>
      <a href="https://scholar.google.com.hk/citations?user=yAWtq6QAAAAJ&hl=en&oi=ao" target="_blank"><font color="#7F7F7F">Naiyan Wang,</font></a>
      <a href="https://scholar.google.com/citations?user=qxWfV6cAAAAJ" target="_blank"><font color="#7F7F7F">Zhaoxiang Zhang</font></a>

      <br>
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a8f7f12b29d9b8c227785f6b529f63b7-Paper-Conference.pdf" target="_blank">Paper (TPAMI)</a>]
      [<a href="https://github.com/BraveGroup/FullySparseFusion" target="_blank">Code</a>]
      </small>

    </td>
  </tr>

  <tr>
    <td width="25%">
      <img style="width: 100%; max-height: 150px; object-fit: cover;" src="./figures/projects/echofusion.png">
    </td>
    <td>
      <strong>Echoes Beyond Points: Unleashing the Power of Raw Radar Data in Multi-modality Fusion</strong>

      <br><small>
      <strong>Yang Liu</strong>,
      <a href="https://scholar.google.com.hk/citations?hl=en&user=GKGSZUoAAAAJ" target="_blank"><font color="#7F7F7F">Feng Wang,</font></a>,
      <a href="https://scholar.google.com.hk/citations?user=yAWtq6QAAAAJ&hl=en&oi=ao" target="_blank"><font color="#7F7F7F">Naiyan Wang,</font></a>
      <a href="https://scholar.google.com/citations?user=qxWfV6cAAAAJ" target="_blank"><font color="#7F7F7F">Zhaoxiang Zhang</font></a>

      <br>
      [<a href="https://proceedings.neurips.cc/paper_files/paper/2023/file/a8f7f12b29d9b8c227785f6b529f63b7-Paper-Conference.pdf" target="_blank">Paper (NeurIPS 2023)</a>]
      [<a href="https://github.com/tusen-ai/EchoFusion" target="_blank">Code</a>]
      </small>

    </td>
  </tr>

  </tr>

</tbody>
</table>
<!-- === Publication Ends === -->


<!-- === Experiences Starts === -->
<br>
<h2>Experiences</h2>
<ul style="font-size: 12pt; text-align: justify;">
<table>
<tbody>
  <tr>
    <td width="30%">
      <code>03/2023 - 01/2024</code>
    </td>
    <td>
      Research intern at <a href="https://www.tusimple.com/" target="_blank">TuSimple</a>
      under the supervision of
      <a href="https://scholar.google.com.hk/citations?hl=en&user=GKGSZUoAAAAJ" target="_blank">Feng Wang</a> and
      <a href="https://scholar.google.com.hk/citations?hl=en&user=yAWtq6QAAAAJ" target="_blank">Naiyan Wang</a>.
    </td>
  </tr>
</tbody>
</table>
</ul>
<!-- === Experiences Ends === -->


<!-- === Academic Service Starts === -->
<br>
<h2>Academic Service</h2>
<p style="font-size: 12pt; text-align: justify;">
  <strong>Conference Reviewer</strong>:
  <ul>
    <li> International Conference on Learning Representations (<strong>ICLR</strong>), 2025 </li>
    </ul>
  <strong>Journal Reviewer</strong>:
  <ul>
  <li> Transactions on Visualization and Computer Graphics (<strong>TVCG</strong>) </li>
  <li> IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>) </li>
  </ul>
</p>
<!-- === Academic Service Ends === -->  


<!-- === Awards Starts === -->
<br>
<h2>Awards</h2>
<ul style="font-size: 12pt; text-align: justify;">
<table>
<tbody>
  <tr>
    <td width="15%">
      <code>04/2022</code>
    </td>
    <td>
      Sichuan Outstanding Graduates (top 0.5%)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2021</code>
    </td>
    <td>
      China National Scholarship (top 0.2%)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2021</code>
    </td>
    <td>
      Gratitude to Modern Chinese Scientists Scholarship (only 12 strudents granted)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2021</code>
    </td>
    <td>
      Most Influential Student of Yingcai Honors College (top 0.2% of all grades)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2021</code>
    </td>
    <td>
      Person of the Year of School of Information and Communication Engineering  (top 0.2% of all grades)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2020</code>
    </td>
    <td>
      China National Encouragement Scholarship
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2019</code>
    </td>
    <td>
      China National Scholarship (top 0.2%)
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>10/2018</code>
    </td>
    <td>
      Champion of "Electronic Cup" Debate Tournament
    </td>
  </tr>

  <tr>
    <td width="15%">
      <code>12/2017</code>
    </td>
    <td>
      First Price in National Olympiad in Physics in Hunan Province
    </td>
  </tr>

</tbody>
</table>
</ul>
<!-- === Awards Ends === -->


</td>
</tr>
</tbody>
</table>
<!-- === Homepage Ends === -->


<!-- Visitor Traffic -->
<script type='text/javascript' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=0&t=tt&d=ZoDwnZl26icJVfh0W6PRaWJC8UIjGa9CyHu2YaqgaRI&co=ffffff&ct=ffffff&cmo=ffffff&cmn=ffffff'></script>


</body>
</html>

